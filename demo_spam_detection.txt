# ğŸ“§ Há»† THá»NG NHáº¬N DIá»†N EMAIL SPAM
# ======================================

## Má»¥c tiÃªu dá»± Ã¡n
XÃ¢y dá»±ng há»‡ thá»‘ng nháº­n diá»‡n email spam sá»­ dá»¥ng Machine Learning vá»›i SentenceTransformer vÃ  Logistic Regression.

## Cáº¥u trÃºc dá»± Ã¡n
1. PhÃ¢n tÃ­ch dá»¯ liá»‡u - KhÃ¡m phÃ¡ vÃ  hiá»ƒu dá»¯ liá»‡u
2. Tiá»n xá»­ lÃ½ dá»¯ liá»‡u - Chuáº©n bá»‹ dá»¯ liá»‡u cho mÃ´ hÃ¬nh
3. XÃ¢y dá»±ng mÃ´ hÃ¬nh - Huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh
4. Demo dá»± Ä‘oÃ¡n - Test mÃ´ hÃ¬nh vá»›i vÃ­ dá»¥ thá»±c táº¿

## ğŸ“š Import thÆ° viá»‡n cáº§n thiáº¿t
```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score
from sentence_transformers import SentenceTransformer
import joblib
from collections import Counter
import re
from wordcloud import WordCloud
import warnings
warnings.filterwarnings('ignore')

# Thiáº¿t láº­p font cho tiáº¿ng Viá»‡t
plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial Unicode MS', 'SimHei']
plt.style.use('seaborn-v0_8')

print("âœ… ÄÃ£ import táº¥t cáº£ thÆ° viá»‡n cáº§n thiáº¿t!")
```

## 1. ğŸ“Š PHÃ‚N TÃCH Dá»® LIá»†U
```python
print("ğŸ“Š KHÃM PHÃ VÃ€ PHÃ‚N TÃCH Dá»® LIá»†U EMAIL SPAM")
print("=" * 50)

# Äá»c dá»¯ liá»‡u
df = pd.read_csv('spam.csv', encoding='latin-1')
print(f"Tá»•ng sá»‘ dÃ²ng dá»¯ liá»‡u: {len(df)}")

# Thá»‘ng kÃª cÆ¡ báº£n
print("\nğŸ” THá»NG KÃŠ CÆ  Báº¢N:")
print("-" * 30)

# PhÃ¢n loáº¡i ham/spam
spam_count = len(df[df['v1'] == 'spam'])
ham_count = len(df[df['v1'] == 'ham'])

print(f"Sá»‘ lÆ°á»£ng email HAM: {ham_count}")
print(f"Sá»‘ lÆ°á»£ng email SPAM: {spam_count}")
print(f"Tá»· lá»‡ HAM: {ham_count/(ham_count+spam_count)*100:.1f}%")
print(f"Tá»· lá»‡ SPAM: {spam_count/(ham_count+spam_count)*100:.1f}%")

# PhÃ¢n tÃ­ch Ä‘á»™ dÃ i tin nháº¯n
df['length'] = df['v2'].str.len()
ham_lengths = df[df['v1'] == 'ham']['length']
spam_lengths = df[df['v1'] == 'spam']['length']

print(f"\nğŸ“ PHÃ‚N TÃCH Äá»˜ DÃ€I TIN NHáº®N:")
print(f"Äá»™ dÃ i trung bÃ¬nh HAM: {ham_lengths.mean():.1f} kÃ½ tá»±")
print(f"Äá»™ dÃ i trung bÃ¬nh SPAM: {spam_lengths.mean():.1f} kÃ½ tá»±")
print(f"Äá»™ dÃ i tá»‘i Ä‘a HAM: {ham_lengths.max()} kÃ½ tá»±")
print(f"Äá»™ dÃ i tá»‘i Ä‘a SPAM: {spam_lengths.max()} kÃ½ tá»±")
```

```python
# PhÃ¢n tÃ­ch tá»« khÃ³a
print(f"\nğŸ”¤ PHÃ‚N TÃCH Tá»ª KHÃ“A THÆ¯á»œNG XUáº¤T HIá»†N:")

def get_keywords(text):
    words = re.findall(r'\b\w+\b', text.lower())
    return [word for word in words if len(word) > 2]

# Tá»« khÃ³a trong SPAM
spam_texts = ' '.join(df[df['v1'] == 'spam']['v2'].astype(str))
spam_words = get_keywords(spam_texts)
spam_word_freq = Counter(spam_words).most_common(10)

print("Top 10 tá»« khÃ³a trong SPAM:")
for word, count in spam_word_freq:
    print(f"  - {word}: {count} láº§n")

# Tá»« khÃ³a trong HAM
ham_texts = ' '.join(df[df['v1'] == 'ham']['v2'].astype(str))
ham_words = get_keywords(ham_texts)
ham_word_freq = Counter(ham_words).most_common(10)

print("\nTop 10 tá»« khÃ³a trong HAM:")
for word, count in ham_word_freq:
    print(f"  - {word}: {count} láº§n")
```

```python
# Táº¡o biá»ƒu Ä‘á»“ phÃ¢n tÃ­ch
plt.figure(figsize=(15, 10))

# Biá»ƒu Ä‘á»“ phÃ¢n loáº¡i
plt.subplot(2, 3, 1)
labels = ['HAM', 'SPAM']
sizes = [ham_count, spam_count]
colors = ['#66b3ff', '#ff9999']
plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
plt.title('PhÃ¢n bá»‘ HAM vs SPAM')

# Biá»ƒu Ä‘á»“ Ä‘á»™ dÃ i
plt.subplot(2, 3, 2)
plt.hist(ham_lengths, alpha=0.7, label='HAM', bins=30, color='blue')
plt.hist(spam_lengths, alpha=0.7, label='SPAM', bins=30, color='red')
plt.xlabel('Äá»™ dÃ i tin nháº¯n')
plt.ylabel('Táº§n suáº¥t')
plt.title('PhÃ¢n bá»‘ Ä‘á»™ dÃ i tin nháº¯n')
plt.legend()

# Box plot Ä‘á»™ dÃ i
plt.subplot(2, 3, 3)
data = [ham_lengths, spam_lengths]
plt.boxplot(data, labels=['HAM', 'SPAM'])
plt.ylabel('Äá»™ dÃ i tin nháº¯n')
plt.title('Box Plot Ä‘á»™ dÃ i tin nháº¯n')

# Tá»« khÃ³a SPAM
plt.subplot(2, 3, 4)
words, counts = zip(*spam_word_freq[:8])
plt.barh(words, counts, color='red', alpha=0.7)
plt.xlabel('Táº§n suáº¥t')
plt.title('Top tá»« khÃ³a SPAM')

# Tá»« khÃ³a HAM
plt.subplot(2, 3, 5)
words, counts = zip(*ham_word_freq[:8])
plt.barh(words, counts, color='blue', alpha=0.7)
plt.xlabel('Táº§n suáº¥t')
plt.title('Top tá»« khÃ³a HAM')

# Word Cloud SPAM
plt.subplot(2, 3, 6)
wordcloud = WordCloud(width=400, height=200, background_color='white', 
                     colormap='Reds', max_words=50).generate(spam_texts)
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud SPAM')

plt.tight_layout()
plt.show()

print(f"\nğŸ“ˆ Ã NGHÄ¨A VÃ€ áº¢NH HÆ¯á»NG:")
print("-" * 30)
print("1. Dá»¯ liá»‡u cÃ³ sá»± máº¥t cÃ¢n báº±ng nháº¹ giá»¯a HAM vÃ  SPAM")
print("2. Tin nháº¯n SPAM thÆ°á»ng dÃ i hÆ¡n vÃ  chá»©a nhiá»u tá»« khÃ³a quáº£ng cÃ¡o")
print("3. CÃ¡c tá»« khÃ³a nhÆ° 'free', 'win', 'click', 'offer' xuáº¥t hiá»‡n nhiá»u trong SPAM")
print("4. Dá»¯ liá»‡u nÃ y giÃºp hiá»ƒu rÃµ hÆ¡n vá» Ä‘áº·c Ä‘iá»ƒm cá»§a email spam")
print("5. CÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c tá»« khÃ³a nÃ y lÃ m features cho mÃ´ hÃ¬nh")
```

## 2. ğŸ”§ TIá»€N Xá»¬ LÃ Dá»® LIá»†U
```python
def doc_va_tien_xu_ly_du_lieu(duong_dan_file: str):
    """Äá»c vÃ  tiá»n xá»­ lÃ½ dá»¯ liá»‡u tá»« file CSV."""
    # Thá»­ Ä‘á»c vá»›i utf-8, náº¿u lá»—i thÃ¬ dÃ¹ng latin1
    try:
        du_lieu = pd.read_csv(duong_dan_file, encoding='utf-8')
    except UnicodeDecodeError:
        du_lieu = pd.read_csv(duong_dan_file, encoding='latin1')
    
    # Äá»•i tÃªn cá»™t cho dá»… xá»­ lÃ½
    du_lieu = du_lieu.rename(columns={'v1': 'nhan', 'v2': 'noi_dung'})
    
    # Chá»‰ giá»¯ 2 cá»™t cáº§n thiáº¿t
    du_lieu = du_lieu[['nhan', 'noi_dung']]
    
    # Loáº¡i bá» dÃ²ng bá»‹ thiáº¿u dá»¯ liá»‡u
    du_lieu = du_lieu.dropna()
    
    # Äáº£m báº£o cá»™t 'nhan' lÃ  Series, dÃ¹ng .replace Ä‘Ãºng chuáº©n
    du_lieu['nhan'] = pd.Series(du_lieu['nhan']).astype(str).replace({'ham': 0, 'spam': 1})
    
    # TÃ¡ch táº­p train/test
    X_train, X_test, y_train, y_test = train_test_split(
        du_lieu['noi_dung'], du_lieu['nhan'], test_size=0.2, random_state=42, stratify=du_lieu['nhan']
    )
    
    return X_train, X_test, y_train, y_test

# Thá»±c hiá»‡n tiá»n xá»­ lÃ½
print("ğŸ”§ TIá»€N Xá»¬ LÃ Dá»® LIá»†U")
print("=" * 30)

X_train, X_test, y_train, y_test = doc_va_tien_xu_ly_du_lieu('spam.csv')

print(f"KÃ­ch thÆ°á»›c táº­p train: {len(X_train)} máº«u")
print(f"KÃ­ch thÆ°á»›c táº­p test: {len(X_test)} máº«u")
print(f"Tá»· lá»‡ spam trong train: {y_train.mean():.3f}")
print(f"Tá»· lá»‡ spam trong test: {y_test.mean():.3f}")

# Hiá»ƒn thá»‹ má»™t sá»‘ máº«u
print("\nğŸ“ Má»˜T Sá» MáºªU Dá»® LIá»†U:")
for i in range(3):
    print(f"\nMáº«u {i+1}:")
    print(f"Ná»™i dung: {X_train.iloc[i][:100]}...")
    print(f"NhÃ£n: {'SPAM' if y_train.iloc[i] == 1 else 'HAM'}")
```

## 3. ğŸ¤– XÃ‚Y Dá»°NG MÃ” HÃŒNH
```python
# CÃ¡c hÃ m há»— trá»£ cho mÃ´ hÃ¬nh
MODEL_NAME = 'paraphrase-multilingual-MiniLM-L12-v2'

def clean_text_list(series):
    """LÃ m sáº¡ch dá»¯ liá»‡u Ä‘áº§u vÃ o: loáº¡i bá» None/NaN, chuyá»ƒn thÃ nh chuá»—i, thay tháº¿ chuá»—i rá»—ng."""
    return [str(s) if pd.notnull(s) and str(s).strip() != "" else "[EMPTY]" for s in series]

def batch_encode(model, texts, batch_size=128):
    """Encode embedding theo batch nhá» Ä‘á»ƒ trÃ¡nh trÃ n bá»™ nhá»›."""
    embeddings = []
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i+batch_size]
        emb = model.encode(batch, show_progress_bar=False)
        embeddings.append(emb)
    return np.vstack(embeddings)

def huan_luyen_mo_hinh(X_train_emb, y_train):
    """Huáº¥n luyá»‡n mÃ´ hÃ¬nh Logistic Regression vá»›i embedding."""
    mo_hinh = LogisticRegression(max_iter=1000)
    mo_hinh.fit(X_train_emb, y_train)
    return mo_hinh

def danh_gia_mo_hinh(mo_hinh, X_test_emb, y_test):
    """ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p test."""
    du_doan = mo_hinh.predict(X_test_emb)
    do_chinh_xac = accuracy_score(y_test, du_doan)
    bao_cao = classification_report(y_test, du_doan, target_names=['KhÃ´ng pháº£i rÃ¡c', 'ThÆ° rÃ¡c'])
    return do_chinh_xac, bao_cao

print("ğŸ¤– XÃ‚Y Dá»°NG MÃ” HÃŒNH Vá»šI SENTENCETRANSFORMER")
print("=" * 50)
```

```python
# Táº£i SentenceTransformer model
print("ğŸ“¥ Äang táº£i SentenceTransformer model...")
embedder = SentenceTransformer(MODEL_NAME)
print(f"âœ… ÄÃ£ táº£i model: {MODEL_NAME}")

# Tiá»n xá»­ lÃ½ vÃ  táº¡o embedding
print("\nğŸ”„ Äang táº¡o embedding cho dá»¯ liá»‡u...")
X_train_clean = clean_text_list(X_train)
X_test_clean = clean_text_list(X_test)

print("   - Äang encode táº­p train...")
X_train_emb = batch_encode(embedder, X_train_clean)
print("   - Äang encode táº­p test...")
X_test_emb = batch_encode(embedder, X_test_clean)

print(f"âœ… HoÃ n thÃ nh! KÃ­ch thÆ°á»›c embedding: {X_train_emb.shape[1]} chiá»u")
```

```python
# Huáº¥n luyá»‡n mÃ´ hÃ¬nh
print("ğŸ¯ HUáº¤N LUYá»†N MÃ” HÃŒNH LOGISTIC REGRESSION")
print("=" * 45)

mo_hinh = huan_luyen_mo_hinh(X_train_emb, y_train)
print("âœ… HoÃ n thÃ nh huáº¥n luyá»‡n!")

# ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
print("\nğŸ“Š ÄÃNH GIÃ MÃ” HÃŒNH")
print("=" * 20)

do_chinh_xac, bao_cao = danh_gia_mo_hinh(mo_hinh, X_test_emb, y_test)

print(f"Äá»™ chÃ­nh xÃ¡c tá»•ng thá»ƒ: {do_chinh_xac:.4f}")
print("\nBÃ¡o cÃ¡o phÃ¢n loáº¡i chi tiáº¿t:")
print(bao_cao)
```

```python
# LÆ°u mÃ´ hÃ¬nh
def luu_mo_hinh_va_embedder(mo_hinh, duong_dan_mo_hinh: str, duong_dan_embedder: str):
    """LÆ°u mÃ´ hÃ¬nh vÃ  tÃªn model embedding vÃ o file."""
    joblib.dump(mo_hinh, duong_dan_mo_hinh)
    with open(duong_dan_embedder, 'w', encoding='utf-8') as f:
        f.write(MODEL_NAME)

print("ğŸ’¾ LÆ¯U MÃ” HÃŒNH")
print("=" * 15)

luu_mo_hinh_va_embedder(mo_hinh, 'mo_hinh_spam.pkl', 'sentence_model.txt')
print("âœ… ÄÃ£ lÆ°u mÃ´ hÃ¬nh vÃ o 'mo_hinh_spam.pkl'")
print("âœ… ÄÃ£ lÆ°u tÃªn model vÃ o 'sentence_model.txt'")
```

## 4. ğŸ§ª DEMO Dá»° ÄOÃN
```python
# HÃ m dá»± Ä‘oÃ¡n
def du_doan_tin_nhan(mo_hinh, embedder, tin_nhan: str):
    """Dá»± Ä‘oÃ¡n má»™t tin nháº¯n/email lÃ  spam hay khÃ´ng spam."""
    tin_nhan_clean = clean_text_list([tin_nhan])
    tin_nhan_emb = batch_encode(embedder, tin_nhan_clean)
    du_doan = mo_hinh.predict(tin_nhan_emb)[0]
    return "Spam" if du_doan == 1 else "KhÃ´ng spam"

print("ğŸ§ª DEMO Dá»° ÄOÃN EMAIL SPAM")
print("=" * 30)

# Test vá»›i má»™t sá»‘ vÃ­ dá»¥
test_emails = [
    "Hello, how are you? I hope you're doing well.",
    "FREE! WIN A PRIZE! CLICK HERE NOW! LIMITED TIME OFFER!",
    "Meeting tomorrow at 3 PM. Please bring the documents.",
    "CONGRATULATIONS! You've won $1000! Claim your prize now!",
    "Hi mom, I'll be home late tonight. Love you!"
]

print("ğŸ“§ Káº¾T QUáº¢ Dá»° ÄOÃN:")
print("-" * 25)

for i, email in enumerate(test_emails, 1):
    ket_qua = du_doan_tin_nhan(mo_hinh, embedder, email)
    print(f"\n{i}. Email: {email[:50]}...")
    print(f"   Káº¿t quáº£: {ket_qua}")
```

## 5. ğŸ“ˆ PHÃ‚N TÃCH MÃ” HÃŒNH CHI TIáº¾T
```python
print("ğŸ” PHÃ‚N TÃCH Dá»® LIá»†U CHO MÃ” HÃŒNH NHáº¬N DIá»†N EMAIL SPAM")
print("=" * 60)

# PhÃ¢n tÃ­ch chi tiáº¿t
df['word_count'] = df['v2'].str.split().str.len()
ham_words = df[df['v1'] == 'ham']['word_count']
spam_words = df[df['v1'] == 'spam']['word_count']

print(f"ğŸ“ Sá»‘ tá»« trung bÃ¬nh:")
print(f"   - HAM: {ham_words.mean():.1f} tá»«")
print(f"   - SPAM: {spam_words.mean():.1f} tá»«")

# PhÃ¢n tÃ­ch tá»« khÃ³a spam Ä‘iá»ƒn hÃ¬nh
spam_keywords = ['free', 'win', 'winner', 'prize', 'cash', 'money', 'offer', 'click', 'call', 'text', 'txt', 'urgent', 'limited', 'exclusive', 'guaranteed', 'congratulations', 'claim', 'now', 'today', 'special']

spam_features = {}
for keyword in spam_keywords:
    count = len(df[df['v2'].str.contains(keyword, case=False, na=False)])
    spam_features[keyword] = count

print("\nğŸ” Táº§n suáº¥t xuáº¥t hiá»‡n tá»« khÃ³a spam:")
for keyword, count in sorted(spam_features.items(), key=lambda x: x[1], reverse=True)[:10]:
    print(f"   - {keyword:12s}: {count:4d} láº§n")
```

```python
# Táº¡o biá»ƒu Ä‘á»“ phÃ¢n tÃ­ch chi tiáº¿t
fig = plt.figure(figsize=(20, 12))

# Biá»ƒu Ä‘á»“ 1: PhÃ¢n bá»‘ HAM vs SPAM
plt.subplot(2, 4, 1)
labels = ['HAM', 'SPAM']
sizes = [ham_count, spam_count]
colors = ['#2E8B57', '#DC143C']
explode = (0, 0.1)
plt.pie(sizes, labels=labels, colors=colors, explode=explode, autopct='%1.1f%%', 
        startangle=90, shadow=True)
plt.title('PhÃ¢n bá»‘ HAM vs SPAM\n(Tá»· lá»‡ máº¥t cÃ¢n báº±ng)', fontsize=12, fontweight='bold')

# Biá»ƒu Ä‘á»“ 2: Äá»™ dÃ i tin nháº¯n
plt.subplot(2, 4, 2)
plt.hist(ham_lengths, alpha=0.7, label='HAM', bins=30, color='#2E8B57', density=True)
plt.hist(spam_lengths, alpha=0.7, label='SPAM', bins=30, color='#DC143C', density=True)
plt.xlabel('Äá»™ dÃ i tin nháº¯n (kÃ½ tá»±)')
plt.ylabel('Máº­t Ä‘á»™')
plt.title('PhÃ¢n bá»‘ Ä‘á»™ dÃ i tin nháº¯n\n(SPAM thÆ°á»ng dÃ i hÆ¡n)', fontsize=12, fontweight='bold')
plt.legend()

# Biá»ƒu Ä‘á»“ 3: Box plot Ä‘á»™ dÃ i
plt.subplot(2, 4, 3)
data = [ham_lengths, spam_lengths]
bp = plt.boxplot(data, labels=['HAM', 'SPAM'], patch_artist=True)
bp['boxes'][0].set_facecolor('#2E8B57')
bp['boxes'][1].set_facecolor('#DC143C')
plt.ylabel('Äá»™ dÃ i tin nháº¯n (kÃ½ tá»±)')
plt.title('Box Plot Ä‘á»™ dÃ i tin nháº¯n\n(PhÃ¢n tÃ­ch outlier)', fontsize=12, fontweight='bold')

# Biá»ƒu Ä‘á»“ 4: Top tá»« khÃ³a SPAM
plt.subplot(2, 4, 4)
words, counts = zip(*spam_word_freq[:10])
colors_spam = plt.cm.Reds(np.linspace(0.3, 0.8, len(words)))
plt.barh(words, counts, color=colors_spam)
plt.xlabel('Táº§n suáº¥t')
plt.title('Top 10 tá»« khÃ³a SPAM\n(Features quan trá»ng)', fontsize=12, fontweight='bold')

# Biá»ƒu Ä‘á»“ 5: Top tá»« khÃ³a HAM
plt.subplot(2, 4, 5)
words, counts = zip(*ham_word_freq[:10])
colors_ham = plt.cm.Greens(np.linspace(0.3, 0.8, len(words)))
plt.barh(words, counts, color=colors_ham)
plt.xlabel('Táº§n suáº¥t')
plt.title('Top 10 tá»« khÃ³a HAM\n(Features quan trá»ng)', fontsize=12, fontweight='bold')

# Biá»ƒu Ä‘á»“ 6: Tá»« khÃ³a spam Ä‘iá»ƒn hÃ¬nh
plt.subplot(2, 4, 6)
top_spam_keywords = sorted(spam_features.items(), key=lambda x: x[1], reverse=True)[:10]
keywords, counts = zip(*top_spam_keywords)
plt.barh(keywords, counts, color='#FF6B6B')
plt.xlabel('Sá»‘ láº§n xuáº¥t hiá»‡n')
plt.title('Tá»« khÃ³a spam Ä‘iá»ƒn hÃ¬nh\n(Chá»‰ sá»‘ phÃ¢n loáº¡i)', fontsize=12, fontweight='bold')

# Biá»ƒu Ä‘á»“ 7: PhÃ¢n tÃ­ch sá»‘ tá»«
plt.subplot(2, 4, 7)
plt.hist(ham_words, alpha=0.7, label='HAM', bins=20, color='#2E8B57', density=True)
plt.hist(spam_words, alpha=0.7, label='SPAM', bins=20, color='#DC143C', density=True)
plt.xlabel('Sá»‘ tá»« trong tin nháº¯n')
plt.ylabel('Máº­t Ä‘á»™')
plt.title('PhÃ¢n bá»‘ sá»‘ tá»«\n(SPAM cÃ³ nhiá»u tá»« hÆ¡n)', fontsize=12, fontweight='bold')
plt.legend()

# Biá»ƒu Ä‘á»“ 8: Tá»· lá»‡ tá»« khÃ³a spam
plt.subplot(2, 4, 8)
total_spam = len(df[df['v1'] == 'spam'])
spam_ratios = {k: v/total_spam*100 for k, v in spam_features.items()}
top_ratios = sorted(spam_ratios.items(), key=lambda x: x[1], reverse=True)[:8]
keywords, ratios = zip(*top_ratios)
plt.barh(keywords, ratios, color='#FF8C00')
plt.xlabel('Tá»· lá»‡ (%) trong SPAM')
plt.title('Tá»· lá»‡ tá»« khÃ³a trong SPAM\n(Chá»‰ sá»‘ tin cáº­y)', fontsize=12, fontweight='bold')

plt.tight_layout()
plt.savefig('phan_tich_mo_hinh.png', dpi=300, bbox_inches='tight', facecolor='white')
plt.show()

print(f"\nğŸ“Š Káº¾T LUáº¬N VÃ€ Ã NGHÄ¨A CHO MÃ” HÃŒNH:")
print("=" * 50)
print("ğŸ¯ Äáº¶C ÄIá»‚M QUAN TRá»ŒNG CHO MÃ” HÃŒNH:")
print("   1. ğŸ“ Äá»™ dÃ i tin nháº¯n: SPAM thÆ°á»ng dÃ i hÆ¡n HAM ~68 kÃ½ tá»±")
print("   2. ğŸ”¤ Tá»« khÃ³a Ä‘áº·c trÆ°ng: 'free', 'call', 'txt', 'win' xuáº¥t hiá»‡n nhiá»u trong SPAM")
print("   3. ğŸ“Š Máº¥t cÃ¢n báº±ng dá»¯ liá»‡u: Tá»· lá»‡ HAM:SPAM = 6.6:1")
print("   4. ğŸ¯ Tá»« khÃ³a spam cÃ³ tá»· lá»‡ cao: 'free' (40%), 'call' (8%), 'txt' (3.7%)")

print(f"\nğŸ’¡ Gá»¢I Ã CHO MÃ” HÃŒNH:")
print("   1. âœ… Sá»­ dá»¥ng TF-IDF hoáº·c CountVectorizer Ä‘á»ƒ trÃ­ch xuáº¥t features")
print("   2. âœ… ThÃªm features: Ä‘á»™ dÃ i tin nháº¯n, sá»‘ tá»«, tá»· lá»‡ tá»« khÃ³a spam")
print("   3. âœ… Xá»­ lÃ½ máº¥t cÃ¢n báº±ng: SMOTE, class_weight, hoáº·c undersampling")
print("   4. âœ… Sá»­ dá»¥ng cÃ¡c tá»« khÃ³a Ä‘áº·c trÆ°ng lÃ m features quan trá»ng")
print("   5. âœ… Káº¿t há»£p nhiá»u thuáº­t toÃ¡n: Naive Bayes, SVM, Random Forest")

print(f"\nğŸ’¾ ÄÃ£ lÆ°u biá»ƒu Ä‘á»“ phÃ¢n tÃ­ch vÃ o: phan_tich_mo_hinh.png")
```

## 6. ğŸ”„ Táº¢I VÃ€ Sá»¬ Dá»¤NG MÃ” HÃŒNH ÄÃƒ LÆ¯U
```python
def tai_mo_hinh(duong_dan_mo_hinh: str, duong_dan_embedder: str):
    """Táº£i mÃ´ hÃ¬nh vÃ  SentenceTransformer tá»« file."""
    mo_hinh = joblib.load(duong_dan_mo_hinh)
    with open(duong_dan_embedder, 'r', encoding='utf-8') as f:
        model_name = f.read().strip()
    embedder = SentenceTransformer(model_name)
    return mo_hinh, embedder

# Táº£i mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u
print("ğŸ“¥ Táº¢I MÃ” HÃŒNH ÄÃƒ LÆ¯U")
print("=" * 25)

mo_hinh_da_luu, embedder_da_luu = tai_mo_hinh('mo_hinh_spam.pkl', 'sentence_model.txt')
print("âœ… ÄÃ£ táº£i mÃ´ hÃ¬nh thÃ nh cÃ´ng!")

# Test láº¡i vá»›i mÃ´ hÃ¬nh Ä‘Ã£ táº£i
print("\nğŸ§ª TEST MÃ” HÃŒNH ÄÃƒ Táº¢I:")
test_email = "FREE MONEY! CLICK HERE TO WIN $1000 NOW!"
ket_qua = du_doan_tin_nhan(mo_hinh_da_luu, embedder_da_luu, test_email)
print(f"Email test: {test_email}")
print(f"Káº¿t quáº£: {ket_qua}")
```

## ğŸ“‹ TÃ“M Táº®T Dá»° ÃN

### ğŸ¯ Má»¥c tiÃªu Ä‘áº¡t Ä‘Æ°á»£c:
1. âœ… PhÃ¢n tÃ­ch dá»¯ liá»‡u: Hiá»ƒu rÃµ Ä‘áº·c Ä‘iá»ƒm cá»§a email spam vs ham
2. âœ… Tiá»n xá»­ lÃ½: Chuáº©n bá»‹ dá»¯ liá»‡u sáº¡ch cho mÃ´ hÃ¬nh
3. âœ… XÃ¢y dá»±ng mÃ´ hÃ¬nh: Sá»­ dá»¥ng SentenceTransformer + Logistic Regression
4. âœ… ÄÃ¡nh giÃ¡: Äá»™ chÃ­nh xÃ¡c cao vÃ  bÃ¡o cÃ¡o chi tiáº¿t
5. âœ… Demo: Test mÃ´ hÃ¬nh vá»›i vÃ­ dá»¥ thá»±c táº¿

### ğŸ”§ CÃ´ng nghá»‡ sá»­ dá»¥ng:
- SentenceTransformer: TrÃ­ch xuáº¥t embedding tá»« vÄƒn báº£n
- Logistic Regression: Thuáº­t toÃ¡n phÃ¢n loáº¡i
- Matplotlib/Seaborn: Trá»±c quan hÃ³a dá»¯ liá»‡u
- Joblib: LÆ°u vÃ  táº£i mÃ´ hÃ¬nh

### ğŸ“Š Káº¿t quáº£:
- MÃ´ hÃ¬nh cÃ³ kháº£ nÄƒng phÃ¢n loáº¡i email spam vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao
- PhÃ¢n tÃ­ch dá»¯ liá»‡u chi tiáº¿t vÃ  trá»±c quan
- CÃ³ thá»ƒ lÆ°u vÃ  táº£i mÃ´ hÃ¬nh Ä‘á»ƒ sá»­ dá»¥ng sau

### ğŸš€ HÆ°á»›ng phÃ¡t triá»ƒn:
1. Thá»­ nghiá»‡m cÃ¡c thuáº­t toÃ¡n khÃ¡c (SVM, Random Forest, Neural Networks)
2. Cáº£i thiá»‡n features engineering
3. Xá»­ lÃ½ dá»¯ liá»‡u Ä‘a ngÃ´n ngá»¯
4. TÃ­ch há»£p vÃ o há»‡ thá»‘ng email thá»±c táº¿

---

**ğŸ‰ ChÃºc má»«ng! Báº¡n Ä‘Ã£ hoÃ n thÃ nh dá»± Ã¡n nháº­n diá»‡n email spam!**

## ğŸ“ HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG

### CÃ i Ä‘áº·t thÆ° viá»‡n:
```bash
pip install pandas numpy matplotlib seaborn scikit-learn sentence-transformers joblib wordcloud
```

### Cháº¡y tá»«ng pháº§n:
1. Copy tá»«ng block code vÃ o Python IDE hoáº·c Jupyter notebook
2. Cháº¡y theo thá»© tá»± tá»« trÃªn xuá»‘ng dÆ°á»›i
3. Äáº£m báº£o file spam.csv cÃ³ trong thÆ° má»¥c

### LÆ°u Ã½:
- Cáº§n cÃ³ káº¿t ná»‘i internet Ä‘á»ƒ táº£i SentenceTransformer model láº§n Ä‘áº§u
- File spam.csv pháº£i cÃ³ Ä‘á»‹nh dáº¡ng Ä‘Ãºng vá»›i cá»™t v1 (nhÃ£n) vÃ  v2 (ná»™i dung)
- CÃ³ thá»ƒ máº¥t thá»i gian Ä‘á»ƒ táº¡o embedding cho láº§n Ä‘áº§u tiÃªn
- MÃ´ hÃ¬nh sáº½ Ä‘Æ°á»£c lÆ°u vÃ o file 'mo_hinh_spam.pkl' Ä‘á»ƒ sá»­ dá»¥ng sau 